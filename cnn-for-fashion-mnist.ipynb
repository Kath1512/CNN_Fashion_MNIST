{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.11.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[{"sourceId":3004,"databundleVersionId":861823,"sourceType":"competition"},{"sourceId":9243,"sourceType":"datasetVersion","datasetId":2243,"isSourceIdPinned":false},{"sourceId":6633136,"sourceType":"datasetVersion","datasetId":3829311}],"dockerImageVersionId":31153,"isInternetEnabled":false,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import os\nimport numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\nfrom PIL import Image\nimport math\nfrom sklearn.model_selection import train_test_split\nfrom scipy.signal import convolve2d\nfrom numpy.lib.stride_tricks import sliding_window_view\nfrom numpy.lib.stride_tricks import as_strided\nfrom sklearn.utils import shuffle\n\nprint(\"Libraries loaded\")\n","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true,"execution":{"iopub.status.busy":"2025-11-07T06:38:44.214585Z","iopub.execute_input":"2025-11-07T06:38:44.214895Z","iopub.status.idle":"2025-11-07T06:38:44.221367Z","shell.execute_reply.started":"2025-11-07T06:38:44.214871Z","shell.execute_reply":"2025-11-07T06:38:44.220198Z"}},"outputs":[{"name":"stdout","text":"Libraries loaded\n","output_type":"stream"}],"execution_count":17},{"cell_type":"code","source":"import kagglehub\n\n# Download latest version\npath = kagglehub.dataset_download(\"zalando-research/fashionmnist\")\n\nprint(\"Path to dataset files:\", path)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-07T06:38:44.222703Z","iopub.execute_input":"2025-11-07T06:38:44.222976Z","iopub.status.idle":"2025-11-07T06:38:44.357644Z","shell.execute_reply.started":"2025-11-07T06:38:44.222957Z","shell.execute_reply":"2025-11-07T06:38:44.356703Z"}},"outputs":[{"name":"stdout","text":"Path to dataset files: /kaggle/input/fashionmnist\n","output_type":"stream"}],"execution_count":18},{"cell_type":"code","source":"base_dir = path\nprint(os.listdir(base_dir))\ntest_path = os.path.join(base_dir, 'fashion-mnist_test.csv')\ntrain_path = os.path.join(base_dir, 'fashion-mnist_train.csv')\nprint(test_path)\nprint(train_path)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-07T06:38:44.358850Z","iopub.execute_input":"2025-11-07T06:38:44.359182Z","iopub.status.idle":"2025-11-07T06:38:44.365567Z","shell.execute_reply.started":"2025-11-07T06:38:44.359134Z","shell.execute_reply":"2025-11-07T06:38:44.364347Z"}},"outputs":[{"name":"stdout","text":"['t10k-labels-idx1-ubyte', 't10k-images-idx3-ubyte', 'fashion-mnist_test.csv', 'fashion-mnist_train.csv', 'train-labels-idx1-ubyte', 'train-images-idx3-ubyte']\n/kaggle/input/fashionmnist/fashion-mnist_test.csv\n/kaggle/input/fashionmnist/fashion-mnist_train.csv\n","output_type":"stream"}],"execution_count":19},{"cell_type":"code","source":"data_test = pd.read_csv(test_path)\ndf_train = pd.read_csv(train_path)\nX = np.asarray(df_train.drop('label', axis=1)) / 255\ny = np.asarray(df_train['label'])\nX_train, X_test, y_train, y_test = train_test_split(\n    X, y, test_size=0.2, random_state=123, shuffle=True\n)\nm_train, _ = X_train.shape\ntest_size = X_test.shape[0]\nimg_size = (28, 28)\nX_train = X_train.reshape(m_train, *img_size, 1)\nX_test = X_test.reshape(test_size, *img_size, 1)\nprint(X_train.shape)\nprint(X_test.shape)\n\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-07T06:38:44.366422Z","iopub.execute_input":"2025-11-07T06:38:44.366695Z","iopub.status.idle":"2025-11-07T06:38:49.127738Z","shell.execute_reply.started":"2025-11-07T06:38:44.366675Z","shell.execute_reply":"2025-11-07T06:38:49.127012Z"}},"outputs":[{"name":"stdout","text":"(48000, 28, 28, 1)\n(12000, 28, 28, 1)\n","output_type":"stream"}],"execution_count":20},{"cell_type":"code","source":"def show_img(data):\n    print(data.shape)\n    plt.imshow(data)\n    plt.show()\nrandom = np.random.randint(0, 100)\nshow_img(X_train[random])\nprint(y_train[random])\n\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-07T06:38:49.130006Z","iopub.execute_input":"2025-11-07T06:38:49.130370Z","iopub.status.idle":"2025-11-07T06:38:49.271946Z","shell.execute_reply.started":"2025-11-07T06:38:49.130350Z","shell.execute_reply":"2025-11-07T06:38:49.271016Z"}},"outputs":[{"name":"stdout","text":"(28, 28, 1)\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"<Figure size 640x480 with 1 Axes>","image/png":"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\n"},"metadata":{}},{"name":"stdout","text":"3\n","output_type":"stream"}],"execution_count":21},{"cell_type":"code","source":"def show_output(output):\n    num_kerns = output.shape[-1]\n    N = math.ceil(num_kerns ** 0.5)\n    fig, axes = plt.subplots(N, N, figsize=(N*1, N*1))\n    for i, ax in enumerate(axes.flatten()):\n        ax.set_title(f\"Image after filter {i}\", fontsize=5)\n        ax.imshow(output[:, :, i], cmap='gray')\n        ax.axis('off')\n    plt.tight_layout()\n    plt.show()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-07T06:38:49.272732Z","iopub.execute_input":"2025-11-07T06:38:49.273021Z","iopub.status.idle":"2025-11-07T06:38:49.278943Z","shell.execute_reply.started":"2025-11-07T06:38:49.273001Z","shell.execute_reply":"2025-11-07T06:38:49.277979Z"}},"outputs":[],"execution_count":22},{"cell_type":"code","source":"def get_padded(inputs, H_pad, W_pad):\n    if H_pad > 0 or W_pad > 0:\n        outputs = np.pad(\n            inputs, \n            ((0, 0), (H_pad, H_pad), (W_pad, W_pad),(0, 0))\n        )\n    else:\n        outputs = inputs\n    return outputs\nclass Layer_Conv:\n    def __init__(self, num_kerns=16, kH=3, kW=3, num_chans=3):\n        self.num_kerns = num_kerns\n        self.kH = kH\n        self.kW = kW\n        self.num_chans = num_chans\n        #parameters\n        limit = np.sqrt(2.0 / (kH * kW * num_chans))\n        self.W = np.random.randn(num_kerns, kH, kW, num_chans) * limit\n        self.b = np.zeros(num_kerns)\n    def forward(self, inputs, padding=0, stride=1):\n        self.stride = stride\n        self.inputs = inputs\n        self.padding = padding\n        # print(\"-----------------------\")\n        # print(\"Convolution Layer: \")\n        #image parameter (200, 128, 128, 3)\n        N, H, W, C = inputs.shape\n        #kernel shape (16, 3, 3, 3)\n        self.N = N\n        num_kerns, kH, kW = self.num_kerns, self.kH, self.kW\n        #output shape (128(batch size), 128, 128, 10)\n        H_out = int((H - kH + padding * 2) / stride + 1)\n        W_out = int((W - kW + padding * 2) / stride + 1)\n        inputs_padded = get_padded(inputs, padding, padding)\n        self.inputs_padded = inputs_padded\n        patches = sliding_window_view(\n            inputs_padded, \n            (kH, kW),                           \n            axis=(1, 2))[:, ::stride, ::stride].transpose(0, 1, 2, 4, 5, 3)\n        outputs = np.tensordot(patches, self.W, axes=([3,4,5],[1,2,3])) #proved (Nimg, H,W,numkerns)\n        outputs = outputs + self.b\n        self.outputs = outputs\n        self.patches = patches\n        # print(\"output shape: \", outputs.shape)\n        # print(\"----------------------------------\")  \n        return self.outputs\n    def backward(self, dA):\n        # res = np.zeros_like(self.W, dtype=float) #(num_kerns, kH, kW, num_chans)\n        # for sample in range(self.samples_size):\n        #     for kernel in range(self.num_kerns):\n        #         for chan in range(self.num_chans):\n        #             for h in range(self.kH):\n        #                 for w in range(self.kW):\n        #                     coef = self.patches[sample, :, :, h, w, chan];\n        #                     res[kernel, h, w, chan] += np.sum(coef * dA[sample, :, :, kernel])\n        # dA shape (n_sample, H, W, num_kerns)\n        # patches shape (n_sample,H,W,kH,kW,numChans)\n        # print(res.shape)\n        # print(np.allclose(dW, res))\n        dZ = dA\n        self.dZ = dZ\n        dW = (1/self.N) * np.tensordot(self.patches, dZ, axes=([0, 1, 2], [0, 1, 2])).transpose(3, 0, 1, 2)\n        db = (1/self.N) * np.sum(dZ, axis=(0, 1, 2))\n        #for dW we can use dW = convolve(inputs, dZ) with stride = 1   \n        #for stride = 2, use convolve(inputs, upsample(dZ))\n        # input_patches = extract_patches(self.inputs_padded, self.kH, self.kW, self.stride)\n        #patches shape (N, H_out, W_out, kH, kW, C)\n        #dZ shape (N, H_out, W_out, num_kerns)\n        # dW_test = np.tensordot(\n        #     self.dZ, input_patches,\n        #     axes=([0, 1, 2], [0, 1, 2])\n        # )\n        #calc dA_prev = full convole(dZ, W_rotate_180)\n        #-> pad dZ -> extract patches -> tensordot\n        W_rot = self.W[:, ::-1, ::-1, :]\n        H_pad, W_pad = self.kH - 1 - self.padding, self.kW - 1 - self.padding\n        dZ_upsample = upsample4d(dZ, self.stride)\n        dZ_pad = get_padded(dZ_upsample, H_pad, W_pad)\n        # dZ_patches = extract_patches(dZ_pad, self.kH, self.kW, 1) #same with below\n        dZ_patches = sliding_window_view(dZ_pad, (self.kH, self.kW), axis=(1, 2))\n        #patches (N, H_up, W_up, numkern, kH, kW)\n        #W_rot (num_kerns, kH, kW, C)\n        dA_prev = np.tensordot(\n            dZ_patches, W_rot,\n            axes=([3,4,5], [0,1,2])\n        )\n        #dA_prev (N, H_in, W_in, C)\n        self.dW = dW\n        self.db = db\n        self.dA_prev = dA_prev\n        # print(\"dA_prev shape: \", dA_prev.shape)\n        return dA_prev\ndef extract_patches(X, kH, kW, stride):\n    N, H_in, W_in, C = X.shape\n    H_out = (H_in - kH)//stride + 1\n    W_out = (W_in - kW)//stride + 1\n    s0, s1, s2, s3 = X.strides\n    patches = as_strided(\n        X, shape=(N, H_out, W_out, kH, kW, C),\n        strides=(s0, s1*stride, s2*stride, s1, s2, s3),\n    )\n    return patches\ndef upsample4d(X, stride):\n    N, H, W, C = X.shape\n    H_up = (H - 1) * (stride - 1) + H\n    W_up = (W - 1) * (stride - 1) + W\n    outputs = np.zeros((N, H_up, W_up, C))\n    outputs[:, ::stride, ::stride, :] = X\n    return outputs\n    \ntest_conv = Layer_Conv(32, 3, 3, 8)\narr = np.random.rand(10, 28, 28, 8)\noutputs = test_conv.forward(arr, 1, 1)\nfake_dA = np.random.rand(*test_conv.outputs.shape)\na = test_conv.backward(fake_dA)\nprint(a.shape)\n\n        \n        \n        ","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-07T06:38:49.280163Z","iopub.execute_input":"2025-11-07T06:38:49.280455Z","iopub.status.idle":"2025-11-07T06:38:49.322947Z","shell.execute_reply.started":"2025-11-07T06:38:49.280433Z","shell.execute_reply":"2025-11-07T06:38:49.322223Z"}},"outputs":[{"name":"stdout","text":"(10, 28, 28, 8)\n","output_type":"stream"}],"execution_count":23},{"cell_type":"code","source":"a = np.random.randint(1, 10, 10)\nwindow = 3\nn = 10\nprint(a)\nstride = a.strides[0]\npatches = as_strided(a, shape=(n - window + 1, window), strides=(stride, stride))\nprint(patches)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-07T06:38:49.323855Z","iopub.execute_input":"2025-11-07T06:38:49.324134Z","iopub.status.idle":"2025-11-07T06:38:49.330295Z","shell.execute_reply.started":"2025-11-07T06:38:49.324115Z","shell.execute_reply":"2025-11-07T06:38:49.329416Z"}},"outputs":[{"name":"stdout","text":"[6 1 3 3 2 2 3 5 8 8]\n[[6 1 3]\n [1 3 3]\n [3 3 2]\n [3 2 2]\n [2 2 3]\n [2 3 5]\n [3 5 8]\n [5 8 8]]\n","output_type":"stream"}],"execution_count":24},{"cell_type":"code","source":"class Layer_Max_Pooling:\n    def forward(self, inputs, kH=2, kW=2, stride=2):\n        # print(\"------------------------------------\")\n        # print(\"Max Pooling Layer\")\n        #inputs are output of conv layer (Nimgs,H,W,num_kernels)\n        patch_shape = (kH, kW)\n        patches = sliding_window_view(inputs, patch_shape, axis=(1, 2))[:, ::stride, ::stride]\n        #patches_shape (N_imgs,H,W,num_chans,kH,kW)\n        outputs = np.max(patches, axis=(-1, -2))\n        masks = (patches == outputs[..., None, None]) #for back prop\n        # print(\"outputs shape: \", outputs.shape)\n        self.inputs = inputs\n        self.outputs = outputs\n        self.masks = masks\n        self.kH = kH\n        self.kW = kW\n        self.stride = stride\n        return self.outputs\n        #checked\n    def backward(self, dA):\n        \"\"\"\n        dA: (N, H_out, W_out, C)\n        masks: (N, H_out, W_out, C, kH, kW)\n        returns: dA_MP (N, H_in, W_in, C)\n        \"\"\"\n        self.dA = dA #(samples_size, H, W, num_chans) e.g (320, 16, 16, 64)\n        # print(dA.shape)\n        samples_size, H, W, num_chans = dA.shape\n        dA_MP = np.zeros_like(self.inputs, dtype=float)\n        stride, kH, kW = self.stride, self.kH, self.kW\n        #masks shape: (N, H_out, W_out, C, kH, kW)\n        patches = self.masks[:, :, :, :] * dA[:, :, :, :, None, None] #(N, H_out, W_out, C, kH, kW)\n        patches = patches.transpose(0, 1, 2, 4, 5, 3) #(N, H_out, W_out, kH, kW, C)\n        for h in range(H):\n            for w in range(W):\n                h_start = h * stride\n                h_end = h_start + kH\n                w_start = w * stride\n                w_end = w_start + kW\n                dA_MP[:, \n                h_start:h_end, \n                w_start:w_end, \n                :] += patches[:, h, w, :, :, :]\n        #check\n        self.outputs = dA_MP\n        return dA_MP\n        \n\narr = np.random.randint(1, 10, (100, 16, 16, 10))\nMP1 = Layer_Max_Pooling()\ndA_fake = MP1.forward(arr, 2, 2, 3)\nres = MP1.backward(dA_fake)\nprint(res.shape)\n\n# show_output(MP1.outputs[0])\n# print(\"---------------------------------------\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-07T06:38:49.331387Z","iopub.execute_input":"2025-11-07T06:38:49.331683Z","iopub.status.idle":"2025-11-07T06:38:49.361058Z","shell.execute_reply.started":"2025-11-07T06:38:49.331656Z","shell.execute_reply":"2025-11-07T06:38:49.360143Z"}},"outputs":[{"name":"stdout","text":"(100, 16, 16, 10)\n","output_type":"stream"}],"execution_count":25},{"cell_type":"code","source":"class ReLu:\n    def forward(self, inputs):\n        self.mask = (inputs > 0)\n        return np.maximum(0, inputs)\n    def backward(self, dA):\n        return dA * self.mask\nclass SoftMax:\n    def forward(self, z): #shape(inputs, sample_size)\n        ez = np.exp(z - np.max(z, axis=0, keepdims=True))\n        self.outputs = ez / np.sum(ez, axis=0, keepdims=True)\n        return self.outputs\n    def backward(self, dA):\n        return dA\n        ","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-07T06:38:49.362039Z","iopub.execute_input":"2025-11-07T06:38:49.362627Z","iopub.status.idle":"2025-11-07T06:38:49.369045Z","shell.execute_reply.started":"2025-11-07T06:38:49.362598Z","shell.execute_reply":"2025-11-07T06:38:49.368207Z"}},"outputs":[],"execution_count":26},{"cell_type":"code","source":"class Flatten:\n    def forward(self, inputs):\n        # print('--------------------------------------')\n        # print('Flatten:')\n        self.inputs = inputs\n        sample_size = inputs.shape[0]\n        outputs = inputs.reshape(sample_size, -1)\n        self.outputs = outputs.T #shape (n_flatten, sample_size)\n        # print('output shape: ', self.outputs.shape)\n        return self.outputs\n    def backward(self, dA):\n        self.dA_flatten = dA # shape: (n_flatten, sample_size)\n        #convert back to -> (samples_size, H, W, num_chan) (320, 16, 16, 64)\n        self.dA_origin = dA.T.reshape(self.inputs.shape)\n        return self.dA_origin\n        \ntest = Flatten()\narr = np.random.rand(12, 16, 16, 32)\nabc = test.forward(arr)\nprint(abc.shape)\nxyz = test.backward(abc)\nprint(np.allclose(arr, xyz))","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-07T06:38:49.371438Z","iopub.execute_input":"2025-11-07T06:38:49.371683Z","iopub.status.idle":"2025-11-07T06:38:49.402877Z","shell.execute_reply.started":"2025-11-07T06:38:49.371658Z","shell.execute_reply":"2025-11-07T06:38:49.401801Z"}},"outputs":[{"name":"stdout","text":"(8192, 12)\nTrue\n","output_type":"stream"}],"execution_count":27},{"cell_type":"code","source":"class Layer_Dense:\n    def __init__(self, n_neurons, n_inputs, activation='relu'):\n        self.n_neurons = n_neurons\n        self.n_inputs = n_inputs #shape (n_flatten, sample_size)\n        limit = np.sqrt(2. / n_inputs) if activation == 'relu' else np.sqrt(1. / n_inputs)\n        self.W = np.random.randn(n_neurons, n_inputs) * limit\n        self.b = np.zeros((n_neurons, 1), dtype=float)\n        # self.W = np.random.rand(n_neurons, n_inputs)\n        # self.b = np.random.rand(n_neurons, 1)\n        if activation == 'relu':\n            self.activation = ReLu()\n        elif activation == 'softmax':\n            self.activation = SoftMax()\n        else:\n            raise ValueError(\"activation must be either relu or softmax\")\n    def forward(self, inputs):\n        self.inputs = inputs\n        self.z = self.W @ inputs + self.b\n        self.A = self.activation.forward(self.z)\n        return self.A\n    def backward(self, dA):\n        dZ = self.activation.backward(dA)\n        m = self.inputs.shape[1]\n        self.dW = (1/m) * (dZ @ self.inputs.T)\n        self.db = (1/m) * np.sum(dZ, axis=1, keepdims=True)\n        dA_prev = self.W.T @ dZ\n        return dA_prev\nclass FC:\n    def __init__(self, n_neurons, n_inputs, n_classes):\n        self.hidden_layer = Layer_Dense(n_neurons, n_inputs, activation='relu')\n        self.output_layer = Layer_Dense(n_classes, n_neurons, activation='softmax')\n        self.n_classes = n_classes\n    def forward(self, inputs):\n        A1 = self.hidden_layer.forward(inputs)\n        self.y_hat = self.output_layer.forward(A1) #(2, sample_size)\n        self.prediction = np.argmax(self.y_hat, axis=0)\n        return self.prediction\n    def backward(self, dA):\n        dA_hidden = self.output_layer.backward(dA)\n        dA_inputs = self.hidden_layer.backward(dA_hidden)\n        return dA_inputs\n#check and test this FC\ndef one_hot(y, n_classes):\n    m = y.shape[0]\n    one_hot_y = np.zeros((n_classes, m))\n    one_hot_y[y, range(len(y))] = 1\n    return one_hot_y\n        ","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-07T06:38:49.403749Z","iopub.execute_input":"2025-11-07T06:38:49.404006Z","iopub.status.idle":"2025-11-07T06:38:49.415105Z","shell.execute_reply.started":"2025-11-07T06:38:49.403987Z","shell.execute_reply":"2025-11-07T06:38:49.414164Z"}},"outputs":[],"execution_count":28},{"cell_type":"code","source":"class MyCNN:\n    def __init__(self, n_inputs_FC, C_in, n_classes):\n        self.Conv = [       \n            Layer_Conv(8, 3, 3, C_in),\n            Layer_Conv(16, 3, 3, 8),\n            Layer_Conv(32, 3, 3, 16)\n        ]\n        self.ReLu = [\n            ReLu(),\n            ReLu(),\n            ReLu()\n        ]\n        self.MP = [\n            Layer_Max_Pooling(),\n            Layer_Max_Pooling(),\n            Layer_Max_Pooling()\n        ]\n        self.Flatten = Flatten()\n        self.FC = FC(128, n_inputs_FC, n_classes)\n        self.n_classes = n_classes\n    def forward(self, inputs):\n        outputs_before = inputs\n        #conv -> relu -> max_pool\n        for i in range(len(self.Conv)):\n            outputs_conv = self.Conv[i].forward(outputs_before, 1, 1)\n            outputs_relu = self.ReLu[i].forward(outputs_conv)\n            outputs_before = self.MP[i].forward(outputs_relu, 2, 2, 2)\n        # #flatten \n        flatten_imgs = self.Flatten.forward(outputs_before)\n        #fully connected layer\n        self.prediction = self.FC.forward(flatten_imgs)\n        self.y_hat = self.FC.y_hat\n        return self.prediction\n    def backward(self, dA):\n        #fully connected layer\n        dA_flatten = self.FC.backward(dA) #shape(n_flatten, n_samples)\n        dA_before_flatten = self.Flatten.backward(dA_flatten) #shape(n_samples,H,W,num_chans)\n        dA_before = dA_before_flatten\n        # print(dA_before.shape)\n        for i in reversed(range(len(self.Conv))):\n            # print(\"Layer: \", i)\n            dA_MP = self.MP[i].backward(dA_before)\n            dA_ReLu = self.ReLu[i].backward(dA_MP)\n            dA_before = self.Conv[i].backward(dA_ReLu)\n        \n        \n        ","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-07T06:51:35.998047Z","iopub.execute_input":"2025-11-07T06:51:35.998401Z","iopub.status.idle":"2025-11-07T06:51:36.007754Z","shell.execute_reply.started":"2025-11-07T06:51:35.998377Z","shell.execute_reply":"2025-11-07T06:51:36.006647Z"}},"outputs":[],"execution_count":53},{"cell_type":"code","source":"def get_accuracy(y_hat, y):\n    return np.sum(y_hat == y) / y.size","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-07T06:38:49.433399Z","iopub.execute_input":"2025-11-07T06:38:49.433683Z","iopub.status.idle":"2025-11-07T06:38:49.453205Z","shell.execute_reply.started":"2025-11-07T06:38:49.433663Z","shell.execute_reply":"2025-11-07T06:38:49.452212Z"}},"outputs":[],"execution_count":30},{"cell_type":"code","source":"def get_batches(X_train, y_train, batch_size):\n    sample_size = X_train.shape[0]\n    total_batches = math.ceil(sample_size / batch_size)\n    for i in range(total_batches):\n        cur_slice = range(i * batch_size, np.minimum((i + 1) * batch_size, sample_size))\n        X_batch = X_train[cur_slice]\n        y_batch = y_train[cur_slice]\n        yield X_batch, y_batch\ndef update_params(lr):\n    #fully connected layer\n        #ouput\n    myCNN.FC.output_layer.W = myCNN.FC.output_layer.W - lr * myCNN.FC.output_layer.dW\n    myCNN.FC.output_layer.b = myCNN.FC.output_layer.b - lr * myCNN.FC.output_layer.db\n        #hidden\n    myCNN.FC.hidden_layer.W = myCNN.FC.hidden_layer.W - lr * myCNN.FC.hidden_layer.dW\n    myCNN.FC.hidden_layer.b = myCNN.FC.hidden_layer.b - lr * myCNN.FC.hidden_layer.db\n    #conv2d layer\n    N_layers = len(myCNN.Conv)\n    for i in reversed(range(N_layers)):\n        # print(myCNN.Conv[i].dW.max(), myCNN.Conv[i].dW.min())\n        myCNN.Conv[i].W -= lr * myCNN.Conv[i].dW\n        myCNN.Conv[i].b -= lr * myCNN.Conv[i].db\ndef get_test(X_test, y_test):\n    N = X_test.shape[0]\n    idx = np.random.choice(N, size=5000, replace=False)\n    X_random, y_random = X_test[idx], y_test[idx]\n    return X_random, y_random\nmyCNN = MyCNN(288, 1, 10)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-07T06:53:05.148283Z","iopub.execute_input":"2025-11-07T06:53:05.148909Z","iopub.status.idle":"2025-11-07T06:53:05.159252Z","shell.execute_reply.started":"2025-11-07T06:53:05.148885Z","shell.execute_reply":"2025-11-07T06:53:05.158228Z"}},"outputs":[],"execution_count":61},{"cell_type":"code","source":"def train(X_train, y_train, epochs=1, batch_size=128, lr=0.01):\n    accuracy_list = []\n    decay_rate = 0.9\n    step = 2\n    init_lr = 0.01\n    for epoch in range(epochs): \n        X_train, y_train = shuffle(X_train, y_train, random_state=42)\n        lr = init_lr * (decay_rate ** (epoch // step))\n        for i, (X_batch, y_batch) in enumerate(get_batches(X_train, y_train, batch_size)):\n            prediction = myCNN.forward(X_batch)\n            dA = myCNN.y_hat - one_hot(y_batch, myCNN.n_classes)\n            accuracy = get_accuracy(prediction, y_batch)\n            accuracy_list.append(accuracy)\n            # print(accuracy, np.unique(prediction, return_counts=True))\n            # print(accuracy, np.unique(myCNN.prediction, return_counts=True))\n            myCNN.backward(dA)\n            update_params(lr)\n            if i % 100 == 0:\n                test_pred = myCNN.forward(X_test)\n                test_accuracy = get_accuracy(test_pred, y_test)\n                print(f\"Epoch {epoch} - Batch {i}: \")\n                print(f\"Training accuracy: \", accuracy)\n                print(f\"Random test accuracy: \", test_accuracy)                   \n        if epoch % 10 == 0:\n            print(f\"Epoch {epoch} - accurarcy {accuracy}\")\nbatch_size = 128\nlr = 0.01 * (0.9 ** 10)\ntrain(X_train, y_train, 10, batch_size, lr)  ","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-07T07:52:05.931718Z","iopub.execute_input":"2025-11-07T07:52:05.932166Z","iopub.status.idle":"2025-11-07T08:06:42.995177Z","shell.execute_reply.started":"2025-11-07T07:52:05.932120Z","shell.execute_reply":"2025-11-07T08:06:42.994166Z"}},"outputs":[{"name":"stdout","text":"Epoch 0 - Batch 0: \nTraining accuracy:  0.96875\nRandom test accuracy:  0.8901666666666667\nEpoch 0 - Batch 100: \nTraining accuracy:  0.90625\nRandom test accuracy:  0.8876666666666667\nEpoch 0 - Batch 200: \nTraining accuracy:  0.8984375\nRandom test accuracy:  0.8841666666666667\nEpoch 0 - Batch 300: \nTraining accuracy:  0.8984375\nRandom test accuracy:  0.8895\nEpoch 0 - accurarcy 0.8828125\nEpoch 1 - Batch 0: \nTraining accuracy:  0.9453125\nRandom test accuracy:  0.88875\nEpoch 1 - Batch 100: \nTraining accuracy:  0.890625\nRandom test accuracy:  0.8904166666666666\nEpoch 1 - Batch 200: \nTraining accuracy:  0.9140625\nRandom test accuracy:  0.88675\nEpoch 1 - Batch 300: \nTraining accuracy:  0.90625\nRandom test accuracy:  0.8916666666666667\nEpoch 2 - Batch 0: \nTraining accuracy:  0.84375\nRandom test accuracy:  0.8925\nEpoch 2 - Batch 100: \nTraining accuracy:  0.9296875\nRandom test accuracy:  0.8911666666666667\nEpoch 2 - Batch 200: \nTraining accuracy:  0.921875\nRandom test accuracy:  0.8900833333333333\nEpoch 2 - Batch 300: \nTraining accuracy:  0.8984375\nRandom test accuracy:  0.8931666666666667\nEpoch 3 - Batch 0: \nTraining accuracy:  0.8828125\nRandom test accuracy:  0.8904166666666666\nEpoch 3 - Batch 100: \nTraining accuracy:  0.8984375\nRandom test accuracy:  0.89025\nEpoch 3 - Batch 200: \nTraining accuracy:  0.8828125\nRandom test accuracy:  0.889\nEpoch 3 - Batch 300: \nTraining accuracy:  0.8984375\nRandom test accuracy:  0.8895833333333333\nEpoch 4 - Batch 0: \nTraining accuracy:  0.90625\nRandom test accuracy:  0.8916666666666667\nEpoch 4 - Batch 100: \nTraining accuracy:  0.859375\nRandom test accuracy:  0.8905\nEpoch 4 - Batch 200: \nTraining accuracy:  0.9375\nRandom test accuracy:  0.8905\nEpoch 4 - Batch 300: \nTraining accuracy:  0.90625\nRandom test accuracy:  0.8870833333333333\nEpoch 5 - Batch 0: \nTraining accuracy:  0.953125\nRandom test accuracy:  0.8888333333333334\nEpoch 5 - Batch 100: \nTraining accuracy:  0.8984375\nRandom test accuracy:  0.89\nEpoch 5 - Batch 200: \nTraining accuracy:  0.9140625\nRandom test accuracy:  0.8913333333333333\nEpoch 5 - Batch 300: \nTraining accuracy:  0.8984375\nRandom test accuracy:  0.8919166666666667\nEpoch 6 - Batch 0: \nTraining accuracy:  0.921875\nRandom test accuracy:  0.8913333333333333\nEpoch 6 - Batch 100: \nTraining accuracy:  0.9140625\nRandom test accuracy:  0.8900833333333333\nEpoch 6 - Batch 200: \nTraining accuracy:  0.875\nRandom test accuracy:  0.89325\nEpoch 6 - Batch 300: \nTraining accuracy:  0.90625\nRandom test accuracy:  0.8943333333333333\nEpoch 7 - Batch 0: \nTraining accuracy:  0.875\nRandom test accuracy:  0.8900833333333333\nEpoch 7 - Batch 100: \nTraining accuracy:  0.890625\nRandom test accuracy:  0.8879166666666667\nEpoch 7 - Batch 200: \nTraining accuracy:  0.890625\nRandom test accuracy:  0.88975\nEpoch 7 - Batch 300: \nTraining accuracy:  0.9140625\nRandom test accuracy:  0.8903333333333333\nEpoch 8 - Batch 0: \nTraining accuracy:  0.9296875\nRandom test accuracy:  0.8930833333333333\nEpoch 8 - Batch 100: \nTraining accuracy:  0.890625\nRandom test accuracy:  0.89225\nEpoch 8 - Batch 200: \nTraining accuracy:  0.9296875\nRandom test accuracy:  0.8928333333333334\nEpoch 8 - Batch 300: \nTraining accuracy:  0.9453125\nRandom test accuracy:  0.8935\nEpoch 9 - Batch 0: \nTraining accuracy:  0.8984375\nRandom test accuracy:  0.8941666666666667\nEpoch 9 - Batch 100: \nTraining accuracy:  0.859375\nRandom test accuracy:  0.8919166666666667\nEpoch 9 - Batch 200: \nTraining accuracy:  0.9140625\nRandom test accuracy:  0.8936666666666667\nEpoch 9 - Batch 300: \nTraining accuracy:  0.9375\nRandom test accuracy:  0.8935\n","output_type":"stream"}],"execution_count":66},{"cell_type":"code","source":"a = [1, 2, 3]\nprint(np.mean(a))","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-07T06:38:49.713286Z","iopub.status.idle":"2025-11-07T06:38:49.713548Z","shell.execute_reply.started":"2025-11-07T06:38:49.713426Z","shell.execute_reply":"2025-11-07T06:38:49.713437Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null}]}